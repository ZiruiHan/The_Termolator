Overview

This project investigates how varying the size of a background corpus affects the quality of domain term extraction using the Termolator tool. By comparing foreground domain texts against general background texts, the Termolator identifies candidate domain terms. Our research shows that while larger background corpora improve recall (capturing more domain terms), they also admit more irrelevant terms, reducing overall precision.

To mitigate this, we integrate an embedding-based semantic filtering step. Using seed domain terms and authoritative glossaries, we compute cosine similarity scores for candidate terms, applying a threshold to filter out semantically distant candidates. This approach enhances precision without sacrificing the benefits of a larger background corpus.

Usage Instructions:
1.labeled_term: contains the 100 manually labelled terms randomly chosen from the out_term_list file for different background corpus
2.term_result: contains the result generated by termolator
3.evulation_precision.py : evaluatoin metrics for calculating precision of manually labeled file in labeled_term
4.AI_Glossary_Terms.txt: the answer key from GLOSSARY OF COMPUTER VISION TERMS by ROBERT M. HARALICK and LINDA G. SHAPIRO
5.computer_vision_answerkey.txt: the answer key from glossary of artificial intelligence in wikipedia
6.word_embedding.py: generating the cosine similarity for each term in out_term_list file and return an average cosine similarity score
7.recall.py: calculat the precision and recall of out_term_list file compared with corresponding answer key
8.similarity_filter.py: filter the term with cosine similarity lower than threshold